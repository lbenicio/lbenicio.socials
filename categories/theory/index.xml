<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Theory on Leonardo Benicio</title><link>https://lbenicio.dev/categories/theory/</link><description>Recent content in Theory on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 27 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/categories/theory/index.xml" rel="self" type="application/rss+xml"/><item><title>The Quiet Calculus of Probabilistic Commutativity</title><link>https://lbenicio.dev/blog/the-quiet-calculus-of-probabilistic-commutativity/</link><pubDate>Sat, 27 Sep 2025 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/the-quiet-calculus-of-probabilistic-commutativity/</guid><description>&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Eventual consistency dominates many internet-scale systems, but reasoning about concurrency under minimal coordination remains ad hoc. This post introduces &amp;ldquo;probabilistic commutativity&amp;rdquo; — a lightweight calculus for reasoning about whether concurrent operations, under reasonable stochastic assumptions about ordering and visibility delays, are likely to commute in practice. Probabilistic commutativity offers an intermediate lens between strict algebraic commutativity and empirical test-driven guarantees, enabling low-overhead coordination strategies and probabilistic correctness arguments for producing practically consistent distributed services.&lt;/p&gt;</description></item><item><title>The Hidden Backbone of Parallelism: How Prefix Sums Power Distributed Computation</title><link>https://lbenicio.dev/blog/the-hidden-backbone-of-parallelism-how-prefix-sums-power-distributed-computation/</link><pubDate>Sun, 21 Sep 2025 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/the-hidden-backbone-of-parallelism-how-prefix-sums-power-distributed-computation/</guid><description>&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When most people think about parallel computing, they imagine splitting a massive task into smaller chunks and running them simultaneously. That’s the Hollywood version: thousands of processors blazing through data, crunching numbers in parallel, and finishing jobs in seconds.&lt;/p&gt;
&lt;p&gt;The reality is both more fascinating and more subtle. Beneath the surface of supercomputers and distributed systems lies a set of seemingly modest mathematical operations—building blocks that make large-scale parallelism possible. Among these, one stands out for its simplicity and profound impact: the &lt;strong&gt;parallel prefix sum&lt;/strong&gt;, also called a &lt;em&gt;scan&lt;/em&gt;.&lt;/p&gt;</description></item><item><title>Bloom Filters and Probabilistic Data Structures: Trading Certainty for Speed</title><link>https://lbenicio.dev/blog/bloom-filters-and-probabilistic-data-structures-trading-certainty-for-speed/</link><pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/bloom-filters-and-probabilistic-data-structures-trading-certainty-for-speed/</guid><description>&lt;p&gt;Sometimes the right answer is &amp;ldquo;probably yes.&amp;rdquo; In a world obsessed with correctness, probabilistic data structures offer a heretical bargain: give up certainty, and in return receive orders-of-magnitude improvements in memory, speed, or both. This post explores the theory and practice behind Bloom filters, Count-Min sketches, HyperLogLog, and their variants—structures that power everything from database query optimization to network traffic analysis at scale.&lt;/p&gt;
&lt;h2 id="1-the-case-for-uncertainty"&gt;1. The Case for Uncertainty&lt;/h2&gt;
&lt;p&gt;Traditional data structures promise exact answers. A hash set tells you definitively whether an element exists. A counter tells you precisely how many times something occurred. But exactness has a cost: memory consumption grows with the number of distinct elements, and lookups may require following chains or probing sequences.&lt;/p&gt;</description></item><item><title>Amdahl’s Law vs. Gustafson’s Law: What They Really Predict</title><link>https://lbenicio.dev/blog/amdahls-law-vs.-gustafsons-law-what-they-really-predict/</link><pubDate>Sat, 15 Jun 2024 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/amdahls-law-vs.-gustafsons-law-what-they-really-predict/</guid><description>&lt;p&gt;Amdahl’s Law and Gustafson’s Law are often presented as opposites, but they model different scenarios.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amdahl assumes a fixed problem size and asks: how much faster can I make this workload with P processors when a fraction s is inherently serial? The upper bound is:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\text{Speedup}_A(P) = \frac{1}{s + \frac{1-s}{P}}.$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gustafson assumes a fixed execution time and asks: given P processors, how much bigger can the problem become if parallel parts scale? The scaled speedup is:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\text{Speedup}_G(P) = s + (1-s),P.$$&lt;/p&gt;</description></item></channel></rss>