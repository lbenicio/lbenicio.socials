<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Systems on Leonardo Benicio</title><link>https://lbenicio.dev/tags/systems/</link><description>Recent content in Systems on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 04 Oct 2025 10:00:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/tags/systems/index.xml" rel="self" type="application/rss+xml"/><item><title>Learned Indexes: When Models Replace B‑Trees</title><link>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</link><pubDate>Sat, 04 Oct 2025 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/learned-indexes-when-models-replace-btrees/</guid><description>&lt;p&gt;If you’ve spent a career trusting B‑trees and hash tables, the idea of using a machine‑learned model as an index can feel like swapping a torque wrench for a Ouija board. But learned indexes aren’t a gimmick. They exploit a simple observation: real data isn’t uniformly random. It has shape—monotonic keys, skewed distributions, natural clusters—and a model can learn that shape to predict where a key lives in a sorted array. The payoff is smaller indexes, fewer cache misses, and—sometimes—dramatically faster lookups.&lt;/p&gt;</description></item><item><title>Memory Allocators: From malloc to Modern Arena Allocators</title><link>https://lbenicio.dev/blog/memory-allocators-from-malloc-to-modern-arena-allocators/</link><pubDate>Thu, 14 Sep 2023 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/memory-allocators-from-malloc-to-modern-arena-allocators/</guid><description>&lt;p&gt;Memory allocation is one of those fundamental operations that most programmers take for granted. You call &lt;code&gt;malloc()&lt;/code&gt;, memory appears; you call &lt;code&gt;free()&lt;/code&gt;, it goes away. But beneath this simple interface lies a fascinating world of algorithms, trade-offs, and optimizations that can make or break your application&amp;rsquo;s performance. This post explores memory allocation from first principles to modern high-performance allocators.&lt;/p&gt;
&lt;h2 id="1-why-memory-allocation-matters"&gt;1. Why Memory Allocation Matters&lt;/h2&gt;
&lt;p&gt;Consider a web server handling thousands of requests per second. Each request might allocate dozens of objects: strings, buffers, data structures. If each allocation takes 1 microsecond, and a request needs 50 allocations, that&amp;rsquo;s 50 microseconds just in allocation overhead—potentially more than the actual request processing time.&lt;/p&gt;</description></item><item><title>Floating Point: How Computers Represent Real Numbers</title><link>https://lbenicio.dev/blog/floating-point-how-computers-represent-real-numbers/</link><pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/floating-point-how-computers-represent-real-numbers/</guid><description>&lt;p&gt;Every programmer eventually encounters the classic puzzle: why does &lt;code&gt;0.1 + 0.2&lt;/code&gt; not equal &lt;code&gt;0.3&lt;/code&gt;? The answer lies in how computers represent real numbers using floating point arithmetic. Understanding IEEE 754 floating point is essential for anyone writing numerical code, financial software, scientific simulations, or graphics applications.&lt;/p&gt;
&lt;h2 id="1-the-challenge-of-representing-real-numbers"&gt;1. The Challenge of Representing Real Numbers&lt;/h2&gt;
&lt;p&gt;Computers work with finite binary representations, but real numbers are infinite.&lt;/p&gt;
&lt;h3 id="11-the-fundamental-problem"&gt;1.1 The Fundamental Problem&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-text" data-lang="text"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Integers are straightforward:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;42 in binary = 101010
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;-7 in binary (two&amp;#39;s complement, 8-bit) = 11111001
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;But real numbers have infinite precision:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;π = 3.14159265358979323846...
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;1/3 = 0.33333333... (repeating)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Even simple decimals can be infinite in binary:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;0.1 (decimal) = 0.0001100110011... (repeating in binary)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="12-why-not-fixed-point"&gt;1.2 Why Not Fixed Point?&lt;/h3&gt;
&lt;p&gt;Fixed point representations dedicate a fixed number of bits to the integer and fractional parts:&lt;/p&gt;</description></item><item><title>CPU Caches and Cache Coherence: The Memory Hierarchy That Makes Modern Computing Fast</title><link>https://lbenicio.dev/blog/cpu-caches-and-cache-coherence-the-memory-hierarchy-that-makes-modern-computing-fast/</link><pubDate>Tue, 12 Jul 2022 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/cpu-caches-and-cache-coherence-the-memory-hierarchy-that-makes-modern-computing-fast/</guid><description>&lt;p&gt;Modern CPUs can execute billions of instructions per second, but main memory takes hundreds of cycles to respond. Without caches, processors would spend most of their time waiting for data. The cache hierarchy is one of the most important innovations in computer architecture, and understanding it is essential for writing high-performance software.&lt;/p&gt;
&lt;h2 id="1-the-memory-wall-problem"&gt;1. The Memory Wall Problem&lt;/h2&gt;
&lt;p&gt;The fundamental challenge that caches solve.&lt;/p&gt;
&lt;h3 id="11-the-speed-gap"&gt;1.1 The Speed Gap&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-text" data-lang="text"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Component Access Time Relative Speed
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;─────────────────────────────────────────────────
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;CPU Register ~0.3 ns 1x (baseline)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;L1 Cache ~1 ns ~3x slower
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;L2 Cache ~3-4 ns ~10x slower
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;L3 Cache ~10-20 ns ~30-60x slower
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Main Memory ~50-100 ns ~150-300x slower
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;NVMe SSD ~20,000 ns ~60,000x slower
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;HDD ~10,000,000 ns ~30,000,000x slower
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="12-why-the-gap-exists"&gt;1.2 Why the Gap Exists&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-text" data-lang="text"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Memory technology tradeoffs:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;SRAM (caches):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Fast: 6 transistors per bit
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Expensive: ~100x cost per bit vs DRAM
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Power hungry
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└─ Low density
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;DRAM (main memory):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Slow: 1 transistor + 1 capacitor per bit
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Cheap: high density
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├─ Needs refresh (capacitors leak)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└─ Better power per bit
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="13-the-solution-caching"&gt;1.3 The Solution: Caching&lt;/h3&gt;
&lt;p&gt;Caches exploit two key principles:&lt;/p&gt;</description></item><item><title>Virtual Memory and Page Tables: How Modern Systems Manage Memory</title><link>https://lbenicio.dev/blog/virtual-memory-and-page-tables-how-modern-systems-manage-memory/</link><pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/virtual-memory-and-page-tables-how-modern-systems-manage-memory/</guid><description>&lt;p&gt;Every process believes it has exclusive access to a vast, contiguous memory space. This elegant illusion—virtual memory—is one of the most important abstractions in computing. Behind it lies a sophisticated system of page tables, TLBs, and hardware-software cooperation that enables memory isolation, efficient sharing, and seemingly infinite memory. Let&amp;rsquo;s explore how it all works.&lt;/p&gt;
&lt;h2 id="1-the-problem-why-virtual-memory"&gt;1. The Problem: Why Virtual Memory?&lt;/h2&gt;
&lt;p&gt;Before virtual memory, programs used physical addresses directly. This created serious problems.&lt;/p&gt;</description></item><item><title>Compiler Optimizations: From Source Code to Fast Machine Code</title><link>https://lbenicio.dev/blog/compiler-optimizations-from-source-code-to-fast-machine-code/</link><pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/compiler-optimizations-from-source-code-to-fast-machine-code/</guid><description>&lt;p&gt;When you compile your code with &lt;code&gt;-O2&lt;/code&gt; or &lt;code&gt;-O3&lt;/code&gt;, something magical happens. The compiler applies dozens of optimization passes that can make your program run 10x faster—or more. Understanding these optimizations helps you write faster code and debug mysterious performance issues. Let&amp;rsquo;s explore how modern compilers transform source code into efficient machine code.&lt;/p&gt;
&lt;h2 id="1-the-compilation-pipeline"&gt;1. The Compilation Pipeline&lt;/h2&gt;
&lt;p&gt;Before diving into optimizations, let&amp;rsquo;s understand where they happen.&lt;/p&gt;
&lt;h3 id="11-compiler-phases"&gt;1.1 Compiler Phases&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-text" data-lang="text"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Source Code
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ▼
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;┌─────────────────┐
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ Front-end │ Parsing, type checking, AST generation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ (Language- │ C, C++, Rust, Swift → IR
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ specific) │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└────────┬────────┘
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ▼
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;┌─────────────────┐
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ Middle-end │ ★ MOST OPTIMIZATIONS HAPPEN HERE ★
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ (IR-based │ Constant folding, inlining, loop opts
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ optimization) │ Dead code elimination, vectorization
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└────────┬────────┘
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ▼
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;┌─────────────────┐
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ Back-end │ Instruction selection, register allocation
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ (Target- │ Instruction scheduling, peephole opts
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ specific) │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└────────┬────────┘
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; │
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ▼
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Machine Code
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="12-intermediate-representation-ir"&gt;1.2 Intermediate Representation (IR)&lt;/h3&gt;
&lt;p&gt;LLVM IR is a popular intermediate representation:&lt;/p&gt;</description></item><item><title>Speculative Prefetchers: Designing Memory Systems That Read the Future</title><link>https://lbenicio.dev/blog/speculative-prefetchers-designing-memory-systems-that-read-the-future/</link><pubDate>Thu, 14 Feb 2019 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/speculative-prefetchers-designing-memory-systems-that-read-the-future/</guid><description>&lt;p&gt;At 2:17 a.m., the on-call performance engineer watches another alert crawl across the dashboard. The new machine image promised higher throughput for a latency-sensitive analytics service, yet caches still thrash whenever end-of-day reconciliation jobs arrive. Each job walks a sparsely linked graph of customer transactions, and the CPU spends more time waiting on memory than executing instructions. &amp;ldquo;If only the hardware could guess where the program was going next,&amp;rdquo; she sighs. That daydream is the seed of speculative prefetching—the art of reading tomorrow’s memory today.&lt;/p&gt;</description></item><item><title>Computer Systems: A Programmer's Perspective (3rd ed.)</title><link>https://lbenicio.dev/reading/computer-systems-a-programmers-perspective-3rd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/computer-systems-a-programmers-perspective-3rd-ed./</guid><description>&lt;p&gt;Bridges programming and computer architecture with a focus on performance and systems.&lt;/p&gt;</description></item><item><title>Computer Systems: A Programmer's Perspective (3rd ed.)</title><link>https://lbenicio.dev/reading/computer-systems-a-programmers-perspective-3rd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/computer-systems-a-programmers-perspective-3rd-ed./</guid><description>&lt;p&gt;Bridges the gap between programming and computer architecture with a focus on performance and systems.&lt;/p&gt;</description></item><item><title>Database System Concepts (7th ed.)</title><link>https://lbenicio.dev/reading/database-system-concepts-7th-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/database-system-concepts-7th-ed./</guid><description>&lt;p&gt;Foundational text on database design, SQL, normalization, transactions, and architectures.&lt;/p&gt;</description></item><item><title>Distributed Systems: Principles and Paradigms (2nd ed.)</title><link>https://lbenicio.dev/reading/distributed-systems-principles-and-paradigms-2nd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/distributed-systems-principles-and-paradigms-2nd-ed./</guid><description>&lt;p&gt;Foundational coverage of distributed system models, communication, consistency, and coordination.&lt;/p&gt;</description></item><item><title>Security Engineering (3rd ed.)</title><link>https://lbenicio.dev/reading/security-engineering-3rd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/security-engineering-3rd-ed./</guid><description>&lt;p&gt;An encyclopedic treatment of security engineering principles, attacks, and defenses.&lt;/p&gt;</description></item></channel></rss>