<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Algorithms on Leonardo Benicio</title><link>https://lbenicio.dev/tags/algorithms/</link><description>Recent content in Algorithms on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 27 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/tags/algorithms/index.xml" rel="self" type="application/rss+xml"/><item><title>The Quiet Calculus of Probabilistic Commutativity</title><link>https://lbenicio.dev/blog/the-quiet-calculus-of-probabilistic-commutativity/</link><pubDate>Sat, 27 Sep 2025 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/the-quiet-calculus-of-probabilistic-commutativity/</guid><description>&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Eventual consistency dominates many internet-scale systems, but reasoning about concurrency under minimal coordination remains ad hoc. This post introduces &amp;ldquo;probabilistic commutativity&amp;rdquo; — a lightweight calculus for reasoning about whether concurrent operations, under reasonable stochastic assumptions about ordering and visibility delays, are likely to commute in practice. Probabilistic commutativity offers an intermediate lens between strict algebraic commutativity and empirical test-driven guarantees, enabling low-overhead coordination strategies and probabilistic correctness arguments for producing practically consistent distributed services.&lt;/p&gt;</description></item><item><title>Bloom Filters and Probabilistic Data Structures: Trading Certainty for Speed</title><link>https://lbenicio.dev/blog/bloom-filters-and-probabilistic-data-structures-trading-certainty-for-speed/</link><pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/bloom-filters-and-probabilistic-data-structures-trading-certainty-for-speed/</guid><description>&lt;p&gt;Sometimes the right answer is &amp;ldquo;probably yes.&amp;rdquo; In a world obsessed with correctness, probabilistic data structures offer a heretical bargain: give up certainty, and in return receive orders-of-magnitude improvements in memory, speed, or both. This post explores the theory and practice behind Bloom filters, Count-Min sketches, HyperLogLog, and their variants—structures that power everything from database query optimization to network traffic analysis at scale.&lt;/p&gt;
&lt;h2 id="1-the-case-for-uncertainty"&gt;1. The Case for Uncertainty&lt;/h2&gt;
&lt;p&gt;Traditional data structures promise exact answers. A hash set tells you definitively whether an element exists. A counter tells you precisely how many times something occurred. But exactness has a cost: memory consumption grows with the number of distinct elements, and lookups may require following chains or probing sequences.&lt;/p&gt;</description></item><item><title>Reverse Indexing and Inverted Files: How Search Engines Fly</title><link>https://lbenicio.dev/blog/reverse-indexing-and-inverted-files-how-search-engines-fly/</link><pubDate>Wed, 19 Jul 2023 10:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/reverse-indexing-and-inverted-files-how-search-engines-fly/</guid><description>&lt;p&gt;Full‑text search is a masterclass in practical data structures. The inverted index—also called a reverse index—maps terms to the list of documents in which they occur. Everything else in a production search engine is optimization: reducing bytes, minimizing random I/O, and avoiding work you don’t have to do.&lt;/p&gt;
&lt;p&gt;In this deep dive we’ll build a complete mental model of inverted files and the techniques that make them fast:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parsing pipeline: tokenization, normalization, stemming/lemmatization, and multilingual realities&lt;/li&gt;
&lt;li&gt;Index structure: vocabulary, postings (doc IDs), term frequencies, and positions for phrase queries&lt;/li&gt;
&lt;li&gt;Compression: delta encoding, Variable‑Byte (VB), Simple‑8b, PForDelta, SIMD‑BP128, QMX, and how they trade space for CPU&lt;/li&gt;
&lt;li&gt;Skipping and acceleration: skip lists, block max indexes, WAND/BMW dynamic pruning&lt;/li&gt;
&lt;li&gt;Scoring: BM25, term and document statistics, field boosts, and normalization&lt;/li&gt;
&lt;li&gt;Updates and merges: segment architecture (Lucene‑style), in‑place deletes, and background compaction&lt;/li&gt;
&lt;li&gt;Caching and tiering: hot vs cold shards, result caching, and Bloom‑like structures&lt;/li&gt;
&lt;li&gt;Distributed search: sharding, replication, and query fan‑out under tail latency pressure&lt;/li&gt;
&lt;li&gt;Measuring and tuning: from recall/precision to p95 query time, heap usage, and GC pauses&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By the end you’ll be able to reason about why each knob exists and which ones matter for your workload.&lt;/p&gt;</description></item><item><title>Garbage Collection Algorithms: From Mark-and-Sweep to ZGC</title><link>https://lbenicio.dev/blog/garbage-collection-algorithms-from-mark-and-sweep-to-zgc/</link><pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/garbage-collection-algorithms-from-mark-and-sweep-to-zgc/</guid><description>&lt;p&gt;Manual memory management is powerful but error-prone. Forget to free memory and you leak; free too early and you corrupt. Garbage collection promises to solve this by automatically reclaiming unused memory. But this convenience comes with costs and trade-offs that every systems programmer should understand. This post explores garbage collection from first principles to cutting-edge concurrent collectors.&lt;/p&gt;
&lt;h2 id="1-why-garbage-collection"&gt;1. Why Garbage Collection?&lt;/h2&gt;
&lt;p&gt;Consider the challenges of manual memory management:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-c" data-lang="c"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff7b72"&gt;void&lt;/span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;process_request&lt;/span&gt;(Request&lt;span style="color:#ff7b72;font-weight:bold"&gt;*&lt;/span&gt; req) {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff7b72"&gt;char&lt;/span&gt;&lt;span style="color:#ff7b72;font-weight:bold"&gt;*&lt;/span&gt; buffer &lt;span style="color:#ff7b72;font-weight:bold"&gt;=&lt;/span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;malloc&lt;/span&gt;(&lt;span style="color:#a5d6ff"&gt;1024&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Result&lt;span style="color:#ff7b72;font-weight:bold"&gt;*&lt;/span&gt; result &lt;span style="color:#ff7b72;font-weight:bold"&gt;=&lt;/span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;compute&lt;/span&gt;(req, buffer);
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff7b72"&gt;if&lt;/span&gt; (result&lt;span style="color:#ff7b72;font-weight:bold"&gt;-&amp;gt;&lt;/span&gt;error) {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8b949e;font-style:italic"&gt;// Oops! Forgot to free buffer
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff7b72"&gt;return&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;send_response&lt;/span&gt;(result);
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;free&lt;/span&gt;(buffer);
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#d2a8ff;font-weight:bold"&gt;free&lt;/span&gt;(result); &lt;span style="color:#8b949e;font-style:italic"&gt;// Did compute() allocate this? Or is it static?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Common bugs include:&lt;/p&gt;</description></item><item><title>Algorithm Design</title><link>https://lbenicio.dev/reading/algorithm-design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/algorithm-design/</guid><description>&lt;p&gt;A practical approach to algorithm design with emphasis on design paradigms and proofs of correctness.&lt;/p&gt;</description></item><item><title>Algorithms</title><link>https://lbenicio.dev/reading/algorithms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/algorithms/</guid><description>&lt;p&gt;An accessible algorithms textbook with strong intuition and mathematical clarity.&lt;/p&gt;</description></item><item><title>Algorithms (4th ed.)</title><link>https://lbenicio.dev/reading/algorithms-4th-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/algorithms-4th-ed./</guid><description>&lt;p&gt;A comprehensive introduction to algorithms with Java implementations and extensive online resources.&lt;/p&gt;</description></item><item><title>Introduction to Algorithms (3rd ed.)</title><link>https://lbenicio.dev/reading/introduction-to-algorithms-3rd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/introduction-to-algorithms-3rd-ed./</guid><description>&lt;p&gt;A comprehensive and rigorous textbook covering algorithms and data structures, widely used in CS curricula.&lt;/p&gt;</description></item><item><title>Introduction to Parallel Computing (2nd ed.)</title><link>https://lbenicio.dev/reading/introduction-to-parallel-computing-2nd-ed./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/introduction-to-parallel-computing-2nd-ed./</guid><description>&lt;p&gt;A comprehensive textbook on models, algorithms, and performance analysis for parallel computing.&lt;/p&gt;</description></item><item><title>The Art of Computer Programming, Vols. 1–4A</title><link>https://lbenicio.dev/reading/the-art-of-computer-programming-vols.-14a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/reading/the-art-of-computer-programming-vols.-14a/</guid><description>&lt;p&gt;Foundational multi-volume work on algorithms, data structures, and analysis of algorithms.&lt;/p&gt;</description></item></channel></rss>