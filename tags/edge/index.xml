<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Edge on Leonardo Benicio</title><link>https://lbenicio.dev/tags/edge/</link><description>Recent content in Edge on Leonardo Benicio</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 16 Aug 2024 10:55:00 +0000</lastBuildDate><atom:link href="https://lbenicio.dev/tags/edge/index.xml" rel="self" type="application/rss+xml"/><item><title>Seeing in the Dark: Observability for Edge AI Fleets</title><link>https://lbenicio.dev/blog/seeing-in-the-dark-observability-for-edge-ai-fleets/</link><pubDate>Fri, 16 Aug 2024 10:55:00 +0000</pubDate><guid>https://lbenicio.dev/blog/seeing-in-the-dark-observability-for-edge-ai-fleets/</guid><description>&lt;p&gt;Our edge AI deployment began with a handful of pilot devices in retail stores. Within months, thousands of cameras, sensors, and point-of-sale terminals joined the fleet. They detected shelves running low, predicted queue lengths, and flagged suspicious transactions. But when a customer called asking why a device misclassified bananas as tennis balls, we realized our observability blurred at the edge. Logs vanished into the ether, metrics arrived sporadically, and models drifted silently. This article shares how we built observability robust enough for flaky networks, sensitive data, and autonomous updates.&lt;/p&gt;</description></item><item><title>Teaching GraphQL to Cache at the Edge</title><link>https://lbenicio.dev/blog/teaching-graphql-to-cache-at-the-edge/</link><pubDate>Sat, 03 Sep 2022 12:15:00 +0000</pubDate><guid>https://lbenicio.dev/blog/teaching-graphql-to-cache-at-the-edge/</guid><description>&lt;p&gt;GraphQL promises tailor-made responses, but tailor-made payloads resist caching. For years, we treated GraphQL responses as ephemeral: generated on demand, personalized, too unique to reuse. Then mobile latency complaints reached a boiling point. Edge locations sat underutilized while origin clusters sweated. We set out to teach GraphQL how to cacheâ€”respecting declarative queries, personalization boundaries, and real-time freshness. This is the story of building an edge caching layer that felt invisible to developers yet shaved hundreds of milliseconds off user interactions.&lt;/p&gt;</description></item><item><title>Designing CRDT-Powered Collaboration Platforms that Stay Consistent</title><link>https://lbenicio.dev/blog/designing-crdt-powered-collaboration-platforms-that-stay-consistent/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://lbenicio.dev/blog/designing-crdt-powered-collaboration-platforms-that-stay-consistent/</guid><description>&lt;p&gt;Real-time collaboration has shifted from a feature to a baseline expectation. Teams sketch ideas in shared whiteboards, edit code together, and annotate product specs while sitting on unreliable networks. Delivering that experience demands more than WebSockets and optimistic UI code. The hard part is consistency: making sure each participant converges on the same state despite offline edits, concurrent operations, and shaky connectivity. Conflict-free replicated data types (CRDTs) emerged as the workhorse that keeps these experiences coherent.&lt;/p&gt;</description></item></channel></rss>